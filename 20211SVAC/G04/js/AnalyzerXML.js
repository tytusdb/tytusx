/* parser generated by jison 0.4.18 */
/*
  Returns a Parser object of the following structure:

  Parser: {
    yy: {}
  }

  Parser.prototype: {
    yy: {},
    trace: function(),
    symbols_: {associative list: name ==> number},
    terminals_: {associative list: number ==> name},
    productions_: [...],
    performAction: function anonymous(yytext, yyleng, yylineno, yy, yystate, $$, _$),
    table: [...],
    defaultActions: {...},
    parseError: function(str, hash),
    parse: function(input),

    lexer: {
        EOF: 1,
        parseError: function(str, hash),
        setInput: function(input),
        input: function(),
        unput: function(str),
        more: function(),
        less: function(n),
        pastInput: function(),
        upcomingInput: function(),
        showPosition: function(),
        test_match: function(regex_match_array, rule_index),
        next: function(),
        lex: function(),
        begin: function(condition),
        popState: function(),
        _currentRules: function(),
        topState: function(),
        pushState: function(condition),

        options: {
            ranges: boolean           (optional: true ==> token location info will include a .range[] member)
            flex: boolean             (optional: true ==> flex-like lexing behaviour where the rules are tested exhaustively to find the longest match)
            backtrack_lexer: boolean  (optional: true ==> lexer regexes are tested in order and for each matching regex the action code is invoked; the lexer terminates the scan when a token is returned by the action code)
        },

        performAction: function(yy, yy_, $avoiding_name_collisions, YY_START),
        rules: [...],
        conditions: {associative list: name ==> set},
    }
  }


  token location info (@$, _$, etc.): {
    first_line: n,
    last_line: n,
    first_column: n,
    last_column: n,
    range: [start_number, end_number]       (where the numbers are indexes into the input string, regular zero-based)
  }


  the parseError function receives a 'hash' object with these members for lexer and parser errors: {
    text:        (matched text)
    token:       (the produced terminal token, if any)
    line:        (yylineno)
  }
  while parser (grammar) errors will also provide these members, i.e. parser errors deliver a superset of attributes: {
    loc:         (yylloc)
    expected:    (string describing the set of expected tokens)
    recoverable: (boolean: TRUE when the parser has a error recovery rule available for this particular error)
  }
*/
var AnalyzerXML = (function(){
var o=function(k,v,o,l){for(o=o||{},l=k.length;l--;o[k[l]]=v);return o},$V0=[1,16],$V1=[1,20],$V2=[1,19],$V3=[1,21],$V4=[2,29],$V5=[1,25],$V6=[1,26],$V7=[1,27],$V8=[1,28],$V9=[1,29],$Va=[1,30],$Vb=[2,5,11],$Vc=[1,35],$Vd=[1,39],$Ve=[1,40],$Vf=[1,41],$Vg=[1,38],$Vh=[2,5,11,29,30,31,32,33,34],$Vi=[1,49],$Vj=[1,53],$Vk=[1,55],$Vl=[1,56],$Vm=[9,13,14,15,17,25,35],$Vn=[1,70],$Vo=[1,73],$Vp=[9,13,14,17,25,35],$Vq=[1,90],$Vr=[1,91],$Vs=[1,92],$Vt=[12,14];
var parser = {trace: function trace () { },
yy: {},
symbols_: {"error":2,"START":3,"XML_STRUCTURE":4,"EOF":5,"PROLOG":6,"NODES":7,"COMMENT":8,"greater_than":9,"TEXTTAG":10,"less_than":11,"question_mark":12,"xml":13,"version":14,"assign":15,"value":16,"encoding":17,"TYPE_ENCODING":18,"NODE":19,"OPENING_TAG":20,"CLOSING_TAG":21,"EMPTY_TAG":22,"IDENTIFIER":23,"ATTRIBS":24,"slash":25,"ATTRIB":26,"TEXT_TAG_CHARS":27,"TEXT_TAG_CHAR":28,"lt":29,"gt":30,"amp":31,"apos":32,"quot":33,"textTag":34,"identifier":35,"exclamation_mark":36,"doble_guion":37,"textComment":38,"utf":39,"iso":40,"ascii":41,"$accept":0,"$end":1},
terminals_: {2:"error",5:"EOF",9:"greater_than",11:"less_than",12:"question_mark",13:"xml",14:"version",15:"assign",16:"value",17:"encoding",25:"slash",29:"lt",30:"gt",31:"amp",32:"apos",33:"quot",34:"textTag",35:"identifier",36:"exclamation_mark",37:"doble_guion",38:"textComment",39:"utf",40:"iso",41:"ascii"},
productions_: [0,[3,2],[3,1],[3,2],[4,2],[4,3],[4,4],[6,12],[6,12],[6,4],[7,2],[7,1],[19,3],[19,2],[19,1],[19,1],[19,4],[19,4],[20,4],[20,5],[21,5],[21,2],[21,5],[22,5],[22,6],[24,2],[24,1],[26,3],[10,1],[10,0],[27,2],[27,1],[28,1],[28,1],[28,1],[28,1],[28,1],[28,1],[23,1],[23,1],[23,1],[23,1],[8,6],[18,1],[18,1],[18,1]],
performAction: function anonymous(yytext, yyleng, yylineno, yy, yystate /* action[1] */, $$ /* vstack */, _$ /* lstack */) {
/* this == yyval */

var $0 = $$.length - 1;
switch (yystate) {
case 1:

        let auxRetorno = new NodoPadre(getId(),"START","-> START","",
                [
                    new NodoPadre(getId(),"XML_STRUCTURE","START -> XML_STRUCTURE EOF","return XML_STRUCTURE.info",$$[$0-1].hijos),
                    new NodoHijo(getId(),"EOF","","")
                ]
            );            
        return {nodos:$$[$0-1].nodos,raizCST:auxRetorno};
        
break;
case 2:
        
        return {nodos:[new Nodo("",    [],    [], Type.COMMENT,     "",    0,             0)]
            ,raizCST:new NodoPadre(getId(),"XML_STRUCTURE","EOF","",[])
            };
    
break;
case 3:

        errores.agregarError("Sintactico","error: "+yytext,this._$.first_line,(this._$.first_column+1));
        return {nodos:[new Nodo("",    [],    [], Type.COMMENT,     "",    0,             0)]
            ,raizCST:new NodoPadre(getId(),"START","error EOF","",[])
            };
    
break;
case 4: case 5:

        this.$ = {nodos:$$[$0].nodos
        ,hijos:[
                new NodoPadre(getId(),"PROLOG","XML_STRUCTURE -> PROLOG NODES","XML_STRUCTURE.info = [PROLOG.valor,NODES.listado]",$$[$0-1].hijos),
                new NodoPadre(getId(),"NODES","","",$$[$0].hijos)
            ]
        };
        
break;
case 6:

        errores.agregarError("Sintactico","error: "+yytext,this._$.first_line,(this._$.first_column+1));
        this.$ = {nodos:[new Nodo("",    [],    [], Type.COMMENT,     "",    0,             0)]
            ,hijos:[new NodoPadre(getId(),"XML_STRUCTURE","error sintactico","",[])]
            };
    
break;
case 7:

        this.$ = {hijos:[
            new NodoHijo(getId(),"<","PROLOG -> &lt;?xml version = value encoding = TYPE_ENCODING ?&gt;","PROLOG.encoding = TYPE_ENCODING.valor"),
            new NodoHijo(getId(),"?","",""),
            new NodoHijo(getId(),"xml","",""),
            new NodoHijo(getId(),"version","",""),
            new NodoHijo(getId(),"=","",""),
            new NodoHijo(getId(),"value","",""),
            new NodoHijo(getId(),"encoding","",""),
            new NodoHijo(getId(),"=","",""),
            new NodoPadre(getId(),"TYPE_ENCODING","","",$$[$0-3].hijos),
            new NodoHijo(getId(),"?","",""),
            new NodoHijo(getId(),">","",""),
            new NodoPadre(getId(),"TEXTTAG","","",$$[$0].hijos),
        ]};
    
break;
case 8:

        this.$ = {hijos:[
            new NodoHijo(getId(),"<","PROLOG -> &lt;?xml version = value encoding = TYPE_ENCODING ?&gt;","PROLOG.encoding = TYPE_ENCODING.valor"),
            new NodoHijo(getId(),"?","",""),
            new NodoHijo(getId(),"xml","",""),
            new NodoHijo(getId(),"encoding","",""),
            new NodoHijo(getId(),"=","",""),
            new NodoPadre(getId(),"TYPE_ENCODING","","",$$[$0-6].hijos),
            new NodoHijo(getId(),"version","",""),
            new NodoHijo(getId(),"=","",""),
            new NodoHijo(getId(),"value","",""),
            new NodoHijo(getId(),"?","",""),
            new NodoHijo(getId(),">","",""),
            new NodoPadre(getId(),"TEXTTAG","","",$$[$0].hijos),
        ]};
    
break;
case 9:

        errores.agregarError("Sintactico","error: "+yytext,this._$.first_line,(this._$.first_column+1));
        this.$ = {nodos:[new Nodo("",    [],    [], Type.COMMENT,     "",    0,             0)]
            ,hijos:[new NodoPadre(getId(),"PROLOG","error sintactico","",[])]
            };
    
break;
case 10:

        $$[$0-1].nodos.push($$[$0].nodo);
        this.$ = {nodos:$$[$0-1].nodos
        ,hijos:[
                new NodoPadre(getId(),"NODES","NODES -> NODES NODE","NODES1.agregar(NODE.valor)<br>NODES.listado = NODES1.listado",$$[$0-1].hijos),
                new NodoPadre(getId(),"NODE","","",$$[$0].hijos)
            ]
        };
        
break;
case 11:

        this.$ = {nodos:[$$[$0].nodo]
            ,hijos:[
                new NodoPadre(getId(),"NODES","NODES -> NODE","NODES.valor = nuevoListado[NODE.valor]",$$[$0].hijos)
            ]
        };
        
break;
case 12:
        
        if($$[$0-2].identificador === $$[$0].identificador){
            this.$ = {nodo:new Nodo($$[$0-2].identificador, $$[$0-2].atributos, $$[$0-1].nodos, Type.DOUBLE_TAG,  $$[$0-2].textoEtiqueta, _$[$0-2].first_line, (_$[$0-2].first_column + 1))
            ,hijos:[
                    new NodoPadre(getId(),"OPENING_TAG","NODE -> OPENING_TAG NODES CLOSING_TAG","NODE.valor = nuevoNodo(NODES.listado)",$$[$0-2].hijos),
                    new NodoPadre(getId(),"NODES","","",$$[$0-1].hijos),
                    new NodoPadre(getId(),"CLOSING_TAG","","",$$[$0].hijos)
                ]
            };
        }else{
            errores.agregarError("Semantico","El id de etiqueta no coincide:<br>&lt;"+$$[$0-2].identificador+"&gt;&lt;/"+$$[$0].identificador+"&gt;",this._$.first_line,(this._$.first_column+1));
            this.$ = {nodo:new Nodo("",    [],    [], Type.COMMENT,     "",    0,             0)
                ,hijos:[new NodoPadre(getId(),"NODE","error semantico","",[])]
                };
        }
        
        
break;
case 13:

        if($$[$0-1].identificador === $$[$0].identificador){
            this.$ = {nodo:new Nodo($$[$0-1].identificador, $$[$0-1].atributos, [], Type.DOUBLE_TAG,  $$[$0-1].textoEtiqueta, _$[$0-1].first_line, (_$[$0-1].first_column + 1))
            ,hijos:[
                    new NodoPadre(getId(),"OPENING_TAG","NODE -> OPENING_TAG CLOSING_TAG","NODE.valor = nuevoNodo()",$$[$0-1].hijos),
                    new NodoPadre(getId(),"CLOSING_TAG","","",$$[$0].hijos)
                ]
            };
        }else{
            errores.agregarError("Semantico","El id de etiqueta no coincide:<br>&lt;"+$$[$0-1].identificador+"&gt;&lt;/"+$$[$0].identificador+"&gt;",this._$.first_line,(this._$.first_column+1));
            this.$ = {nodo:new Nodo("",    [],    [], Type.COMMENT,     "",    0,             0)
                ,hijos:[new NodoPadre(getId(),"NODE","error sematico","",[])]
                };
        }
        
break;
case 14:

        this.$ = {nodo:new Nodo($$[$0].identificador, $$[$0].atributos, [], Type.EMPTY,       $$[$0].textoEtiqueta, _$[$0].first_line, (_$[$0].first_column + 1))
        ,hijos:[
                new NodoPadre(getId(),"EMPTY_TAG","NODE -> EMPTY_TAG","NODE.valor = nuevoNodo()",$$[$0].hijos)
            ]
        };
        
break;
case 15:

        this.$ = {nodo:new Nodo("",    [],    [], Type.COMMENT,     "",    0,             0),
            hijos:[]
        };

        
break;
case 16: case 17:

        errores.agregarError("Sintactico","error: "+yytext,this._$.first_line,(this._$.first_column+1));
        this.$ = {nodo:new Nodo("",    [],    [], Type.COMMENT,     "",    0,             0)
            ,hijos:[new NodoPadre(getId(),"NODE","error sintactico","",[])]
            };
    
break;
case 18:

        this.$={identificador:$$[$0-2].contenido
            ,textoEtiqueta:$$[$0].contenido
            ,atributos:[]
            ,hijos:[
                new NodoHijo(getId(),"<","OPENING_TAG -> < IDENTIFIER > TEXTTAG","OPENING_TAG.info = [IDENTIFIER.valor, TEXTAG.valor, ATTRIBS.listado]"),
                new NodoPadre(getId(),"IDENTIFIER","","",$$[$0-2].hijos),
                new NodoHijo(getId(),">","",""),
                new NodoPadre(getId(),"TEXTTAG","","",$$[$0].hijos)
            ]
        };

        
break;
case 19:
        
        this.$={identificador:$$[$0-3].contenido
            ,textoEtiqueta:$$[$0].contenido
            ,atributos:$$[$0-2].atributos
            ,hijos:[
                new NodoHijo(getId(),"<","OPENING_TAG -> < IDENTIFIER ATRIBS > TEXTTAG","OPENING_TAG.info = [IDENTIFIER.valor, TEXTAG.valor, ATTRIBS.listado]"),
                new NodoPadre(getId(),"IDENTIFIER","","",$$[$0-3].hijos),
                new NodoPadre(getId(),"ATRIBS","","",$$[$0-2].hijos),
                new NodoHijo(getId(),">","",""),
                new NodoPadre(getId(),"TEXTTAG","","",$$[$0].hijos)
            ]
        };
        
break;
case 20:

        this.$ = {identificador:$$[$0-2].contenido
                ,hijos:[
                    new NodoHijo(getId(),"<","CLOSING_TAG -> < / IDENTIFIER > TEXTTAG","CLOSING_TAG.valor = IDENTIFIER.valor"),
                    new NodoHijo(getId(),"/","",""),
                    new NodoPadre(getId(),"IDENTIFIER","","",$$[$0-2].hijos),
                    new NodoHijo(getId(),">","",""),
                    new NodoPadre(getId(),"TEXTTAG","","",$$[$0].hijos)
            ]
            };
        
break;
case 21:

        errores.agregarError("Sintactico","error: "+yytext,this._$.first_line,(this._$.first_column+1));
        this.$ = {nodos:new Nodo("",    [],    [], Type.COMMENT,     "",    0,             0)
            ,hijos:[new NodoPadre(getId(),"CLOSING_TAG","error sintactico","",[])]
            };
    
break;
case 22:

        errores.agregarError("Sintactico","error: "+yytext,this._$.first_line,(this._$.first_column+1));
        this.$ = {nodos:new new Nodo("",    [],    [], Type.COMMENT,     "",    0,             0)
            ,hijos:[new NodoPadre(getId(),"CLOSING_TAG","error sintactico","",[])]
            };
    
break;
case 23:

            this.$={identificador:$$[$0-3].contenido
                ,textoEtiqueta: $$[$0].contenido
                ,atributos:[]
                ,hijos:[
                    new NodoHijo(getId(),"<","EMPTY_TAG -> < IDENTIFIER / > ","EMPTY_TAG.info = [IDENTIFIER.valor, TEXTAG.valor, ATTRIBS.listado]"),
                    new NodoPadre(getId(),"IDENTIFIER","","",$$[$0-3].hijos),
                    new NodoHijo(getId(),"/","",""),
                    new NodoHijo(getId(),">","",""),
                    new NodoPadre(getId(),"TEXTTAG","","",$$[$0].hijos)
                ]
            };

            
break;
case 24:

        this.$={identificador:$$[$0-4].contenido
            ,textoEtiqueta: $$[$0].contenido
            ,atributos: $$[$0-3].atributos
            ,hijos:[
                    new NodoHijo(getId(),"<","EMPTY_TAG -> < IDENTIFIER ATRIBS / > TEXTTAG","EMPTY_TAG.info = [IDENTIFIER.valor, TEXTAG.valor, ATTRIBS.listado]"),
                    new NodoPadre(getId(),"IDENTIFIER","","",$$[$0-4].hijos),
                    new NodoPadre(getId(),"ATRIBS","","",$$[$0-3].hijos),
                    new NodoHijo(getId(),"/","",""),
                    new NodoHijo(getId(),">","",""),
                    new NodoPadre(getId(),"TEXTTAG","","",$$[$0].hijos)
                ]
        };
        
break;
case 25:

            $$[$0-1].atributos.push($$[$0].atributo);            
            this.$ = {atributos:$$[$0-1].atributos
                ,hijos:[
                    new NodoPadre(getId(),"ATRIBS","ATRIBS -> ATRIBS ATRIB","ATRIB1.agregar(ATRIB.valor)<br>ATRIBS.listado = ATRIB1.listado",$$[$0-1].hijos),
                    new NodoPadre(getId(),"ATRIB","","",$$[$0].hijos)
                ]
            };
            
break;
case 26:

            this.$ = {atributos:[ $$[$0].atributo ], hijos:[ new NodoPadre(getId(),"ATRIB","ATRIBS -> ATRIB","ATRIBS.valor = nuevoListado[ATRIB.valor]",$$[$0].hijos) ] };
        
break;
case 27:

        this.$ = {atributo:
            new Atributo($$[$0-2].contenido,$$[$0].replaceAll('\"', ""), Type.ATRIBUTO, _$[$0-2].first_line, (_$[$0-2].first_column + 1))
            ,hijos:[
                new NodoPadre(getId(),"IDENTIFIER","ATRIB -> IDENTIFIER = value","ATRIB.valor=value.lexicoValor",$$[$0-2].hijos),
                new NodoHijo(getId(),"=","",""),
                new NodoHijo(getId(),"value","","")
            ]
        }
        ;
break;
case 28:

        this.$ = {contenido: $$[$0].contenido,
                hijos:[
                    new NodoPadre(getId(),"TEXT_TAG_CHAR","TEXTTAG -> TEXT_TAG_CHARS","TEXTTAG.valor = TEXT_TAG_CHARS.valor",$$[$0].hijos)
                ]
            };
        
break;
case 29:

        this.$ = {contenido:"",hijos:[new NodoHijo(getId(),"lambda","TEXTTAG -> lambda ","")]};
        
break;
case 30:

        this.$ = {contenido: $$[$0-1].contenido + $$[$0].contenido,
        hijos:[
            new NodoPadre(getId(),"TEXT_TAG_CHAR","TEXT_TAG_CHARS -> TEXT_TAG_CHARS TEXT_TAG_CHAR","TEXT_TAG_CHARS.valor = TEXT_TAG_CHARS.valor + TEXT_TAG_CHAR.valor",[$$[$0-1].hijos]),
            new NodoPadre(getId(),"TEXT_TAG_CHARS","","",$$[$0-1].hijos)
        ]};
        
break;
case 31:

        this.$ = {contenido:$$[$0].contenido,
            hijos:[
                new NodoPadre(getId(),"TEXT_TAG_CHAR","TEXT_TAG_CHARS -> TEXT_TAG_CHAR","TEXT_TAG_CHARS.valor = TEXT_TAG_CHAR.valor",[$$[$0].hijos])
            ]
        };
        
break;
case 32:
this.$ = {contenido:"<"            ,hijos:new NodoHijo(getId(),$$[$0],"TEXT_TAG_CHAR -> "+$$[$0],"TEXT_TAG_CHAR.valor = "+$$[$0]+".lexicoValor")};
break;
case 33:
this.$ = {contenido:">"            ,hijos:new NodoHijo(getId(),$$[$0],"TEXT_TAG_CHAR -> "+$$[$0],"TEXT_TAG_CHAR.valor = "+$$[$0]+".lexicoValor")};
break;
case 34:
this.$ = {contenido:"&"            ,hijos:new NodoHijo(getId(),$$[$0],"TEXT_TAG_CHAR -> "+$$[$0],"TEXT_TAG_CHAR.valor = "+$$[$0]+".lexicoValor")};
break;
case 35:
this.$ = {contenido:"'"            ,hijos:new NodoHijo(getId(),$$[$0],"TEXT_TAG_CHAR -> "+$$[$0],"TEXT_TAG_CHAR.valor = "+$$[$0]+".lexicoValor")};
break;
case 36:
this.$ = {contenido:"\""           ,hijos:new NodoHijo(getId(),$$[$0],"TEXT_TAG_CHAR -> "+$$[$0],"TEXT_TAG_CHAR.valor = "+$$[$0]+".lexicoValor")};
break;
case 37:
this.$ = {contenido:$$[$0].trim()      ,hijos:new NodoHijo(getId(),$$[$0],"TEXT_TAG_CHAR -> "+$$[$0],"TEXT_TAG_CHAR.valor = "+$$[$0]+".lexicoValor")};
break;
case 38:
this.$ = {contenido:$$[$0]             ,hijos:[new NodoHijo(getId(),$$[$0],"IDENTIFIER -> identifier","IDENTIFIER.valor = identifier.lexicoValor")]};
break;
case 39:
this.$ = {contenido:$$[$0]             ,hijos:[new NodoHijo(getId(),$$[$0],"IDENTIFIER -> xml"       ,"IDENTIFIER.valor = xml.lexicoValor")]};
break;
case 40:
this.$ = {contenido:$$[$0]             ,hijos:[new NodoHijo(getId(),$$[$0],"IDENTIFIER -> version"   ,"IDENTIFIER.valor = version.lexicoValor")]};
break;
case 41:
this.$ = {contenido:$$[$0]             ,hijos:[new NodoHijo(getId(),$$[$0],"IDENTIFIER -> encoding"  ,"IDENTIFIER.valor = encoding.lexicoValor")]};
break;
case 43:
this.$ = {contenido:$$[$0]             ,hijos:[new NodoHijo(getId(),$$[$0],"TYPE_ENCODING -> "+$$[$0],"TYPE_ENCODING.valor = uft.lexicoValor")]};
break;
case 44:
this.$ = {contenido:$$[$0]             ,hijos:[new NodoHijo(getId(),$$[$0],"TYPE_ENCODING -> "+$$[$0],"TYPE_ENCODING.valor = iso.lexicoValor")]};
break;
case 45:
this.$ = {contenido:$$[$0]             ,hijos:[new NodoHijo(getId(),$$[$0],"TYPE_ENCODING -> "+$$[$0],"TYPE_ENCODING.valor = ascii.lexicoValor")]};
break;
}
},
table: [{2:[1,4],3:1,4:2,5:[1,3],6:5,8:6,11:[1,7]},{1:[3]},{5:[1,8]},{1:[2,2]},{5:[1,9],9:[1,10]},{7:11,8:15,11:$V0,19:12,20:13,22:14},{6:17,11:[1,18]},{2:$V1,12:$V2,36:$V3},{1:[2,1]},{1:[2,3]},{10:22,11:$V4,27:23,28:24,29:$V5,30:$V6,31:$V7,32:$V8,33:$V9,34:$Va},{5:[2,4],8:15,11:$V0,19:31,20:13,22:14},o($Vb,[2,11]),{2:[1,34],7:32,8:15,11:$Vc,19:12,20:13,21:33,22:14},o($Vb,[2,14]),o($Vb,[2,15]),{2:[1,36],13:$Vd,14:$Ve,17:$Vf,23:37,35:$Vg,36:$V3},{7:42,8:15,11:$V0,19:12,20:13,22:14},{2:$V1,12:$V2},{13:[1,43]},{9:[1,44]},{37:[1,45]},{7:46,8:15,11:$V0,19:12,20:13,22:14},o($Vb,[2,28],{28:47,29:$V5,30:$V6,31:$V7,32:$V8,33:$V9,34:$Va}),o($Vh,[2,31]),o($Vh,[2,32]),o($Vh,[2,33]),o($Vh,[2,34]),o($Vh,[2,35]),o($Vh,[2,36]),o($Vh,[2,37]),o($Vb,[2,10]),{2:$Vi,8:15,11:$Vc,19:31,20:13,21:48,22:14},o($Vb,[2,13]),{2:$Vi,11:[1,52],20:51,21:50},{2:[1,54],13:$Vd,14:$Ve,17:$Vf,23:37,25:$Vj,35:$Vg,36:$V3},{9:$Vk},{9:$Vl,13:$Vd,14:$Ve,17:$Vf,23:60,24:57,25:[1,58],26:59,35:$Vg},o($Vm,[2,38]),o($Vm,[2,39]),o($Vm,[2,40]),o($Vm,[2,41]),{5:[2,5],8:15,11:$V0,19:31,20:13,22:14},{14:[1,61],17:[1,62]},{10:63,11:$V4,27:23,28:24,29:$V5,30:$V6,31:$V7,32:$V8,33:$V9,34:$Va},{38:[1,64]},{5:[2,6],8:15,11:$V0,19:31,20:13,22:14},o($Vh,[2,30]),o($Vb,[2,12]),{11:[1,65],20:51},{5:[1,66]},o($Vb,[2,21]),{2:[1,67],13:$Vd,14:$Ve,17:$Vf,23:68,25:$Vj,35:$Vg},{13:$Vd,14:$Ve,17:$Vf,23:69,35:$Vg},{9:$Vk,25:$Vn},o($Vb,$V4,{27:23,28:24,10:71,29:$V5,30:$V6,31:$V7,32:$V8,33:$V9,34:$Va}),o($Vb,$V4,{27:23,28:24,10:72,29:$V5,30:$V6,31:$V7,32:$V8,33:$V9,34:$Va}),{9:$Vo,13:$Vd,14:$Ve,17:$Vf,23:60,25:[1,74],26:75,35:$Vg},{9:[1,76]},o($Vp,[2,26]),{15:[1,77]},{15:[1,78]},{15:[1,79]},{11:[2,9]},{37:[1,80]},{13:$Vd,14:$Ve,17:$Vf,23:68,35:$Vg},o($Vb,[2,17]),{25:$Vn},{9:$Vl,13:$Vd,14:$Ve,17:$Vf,23:60,24:81,26:59,35:$Vg},{9:[1,82]},{9:[1,83]},o($Vb,[2,16]),o($Vb,[2,18]),o($Vb,$V4,{27:23,28:24,10:84,29:$V5,30:$V6,31:$V7,32:$V8,33:$V9,34:$Va}),{9:[1,85]},o($Vp,[2,25]),o($Vb,$V4,{27:23,28:24,10:86,29:$V5,30:$V6,31:$V7,32:$V8,33:$V9,34:$Va}),{16:[1,87]},{16:[1,88]},{18:89,39:$Vq,40:$Vr,41:$Vs},{9:[1,93]},{9:$Vo,13:$Vd,14:$Ve,17:$Vf,23:60,26:75,35:$Vg},o($Vb,$V4,{27:23,28:24,10:94,29:$V5,30:$V6,31:$V7,32:$V8,33:$V9,34:$Va}),o($Vb,$V4,{27:23,28:24,10:95,29:$V5,30:$V6,31:$V7,32:$V8,33:$V9,34:$Va}),o($Vb,[2,19]),o($Vb,$V4,{27:23,28:24,10:96,29:$V5,30:$V6,31:$V7,32:$V8,33:$V9,34:$Va}),o($Vb,[2,23]),o($Vp,[2,27]),{17:[1,97]},{14:[1,98]},o($Vt,[2,43]),o($Vt,[2,44]),o($Vt,[2,45]),o($Vb,[2,42]),o($Vb,[2,20]),o($Vb,[2,22]),o($Vb,[2,24]),{15:[1,99]},{15:[1,100]},{18:101,39:$Vq,40:$Vr,41:$Vs},{16:[1,102]},{12:[1,103]},{12:[1,104]},{9:[1,105]},{9:[1,106]},{10:107,11:$V4,27:23,28:24,29:$V5,30:$V6,31:$V7,32:$V8,33:$V9,34:$Va},{10:108,11:$V4,27:23,28:24,29:$V5,30:$V6,31:$V7,32:$V8,33:$V9,34:$Va},{11:[2,7]},{11:[2,8]}],
defaultActions: {3:[2,2],8:[2,1],9:[2,3],63:[2,9],107:[2,7],108:[2,8]},
parseError: function parseError (str, hash) {
    if (hash.recoverable) {
        this.trace(str);
    } else {
        var error = new Error(str);
        error.hash = hash;
        throw error;
    }
},
parse: function parse (input) {
    var self = this,
        stack = [0],
        tstack = [], // token stack
        vstack = [null], // semantic value stack
        lstack = [], // location stack
        table = this.table,
        yytext = '',
        yylineno = 0,
        yyleng = 0,
        recovering = 0,
        TERROR = 2,
        EOF = 1;

    var args = lstack.slice.call(arguments, 1);

    //this.reductionCount = this.shiftCount = 0;

    var lexer = Object.create(this.lexer);
    var sharedState = { yy: {} };
    // copy state
    for (var k in this.yy) {
      if (Object.prototype.hasOwnProperty.call(this.yy, k)) {
        sharedState.yy[k] = this.yy[k];
      }
    }

    lexer.setInput(input, sharedState.yy);
    sharedState.yy.lexer = lexer;
    sharedState.yy.parser = this;
    if (typeof lexer.yylloc == 'undefined') {
        lexer.yylloc = {};
    }
    var yyloc = lexer.yylloc;
    lstack.push(yyloc);

    var ranges = lexer.options && lexer.options.ranges;

    if (typeof sharedState.yy.parseError === 'function') {
        this.parseError = sharedState.yy.parseError;
    } else {
        this.parseError = Object.getPrototypeOf(this).parseError;
    }

    function popStack (n) {
        stack.length = stack.length - 2 * n;
        vstack.length = vstack.length - n;
        lstack.length = lstack.length - n;
    }

_token_stack:
    var lex = function () {
        var token;
        token = lexer.lex() || EOF;
        // if token isn't its numeric value, convert
        if (typeof token !== 'number') {
            token = self.symbols_[token] || token;
        }
        return token;
    }

    var symbol, preErrorSymbol, state, action, a, r, yyval = {}, p, len, newState, expected;
    while (true) {
        // retreive state number from top of stack
        state = stack[stack.length - 1];

        // use default actions if available
        if (this.defaultActions[state]) {
            action = this.defaultActions[state];
        } else {
            if (symbol === null || typeof symbol == 'undefined') {
                symbol = lex();
            }
            // read action for current state and first input
            action = table[state] && table[state][symbol];
        }

_handle_error:
        // handle parse error
        if (typeof action === 'undefined' || !action.length || !action[0]) {
            var error_rule_depth;
            var errStr = '';

            // Return the rule stack depth where the nearest error rule can be found.
            // Return FALSE when no error recovery rule was found.
            function locateNearestErrorRecoveryRule(state) {
                var stack_probe = stack.length - 1;
                var depth = 0;

                // try to recover from error
                for(;;) {
                    // check for error recovery rule in this state
                    if ((TERROR.toString()) in table[state]) {
                        return depth;
                    }
                    if (state === 0 || stack_probe < 2) {
                        return false; // No suitable error recovery rule available.
                    }
                    stack_probe -= 2; // popStack(1): [symbol, action]
                    state = stack[stack_probe];
                    ++depth;
                }
            }

            if (!recovering) {
                // first see if there's any chance at hitting an error recovery rule:
                error_rule_depth = locateNearestErrorRecoveryRule(state);

                // Report error
                expected = [];
                for (p in table[state]) {
                    if (this.terminals_[p] && p > TERROR) {
                        expected.push("'"+this.terminals_[p]+"'");
                    }
                }
                if (lexer.showPosition) {
                    errStr = 'Parse error on line '+(yylineno+1)+":\n"+lexer.showPosition()+"\nExpecting "+expected.join(', ') + ", got '" + (this.terminals_[symbol] || symbol)+ "'";
                } else {
                    errStr = 'Parse error on line '+(yylineno+1)+": Unexpected " +
                                  (symbol == EOF ? "end of input" :
                                              ("'"+(this.terminals_[symbol] || symbol)+"'"));
                }
                this.parseError(errStr, {
                    text: lexer.match,
                    token: this.terminals_[symbol] || symbol,
                    line: lexer.yylineno,
                    loc: yyloc,
                    expected: expected,
                    recoverable: (error_rule_depth !== false)
                });
            } else if (preErrorSymbol !== EOF) {
                error_rule_depth = locateNearestErrorRecoveryRule(state);
            }

            // just recovered from another error
            if (recovering == 3) {
                if (symbol === EOF || preErrorSymbol === EOF) {
                    throw new Error(errStr || 'Parsing halted while starting to recover from another error.');
                }

                // discard current lookahead and grab another
                yyleng = lexer.yyleng;
                yytext = lexer.yytext;
                yylineno = lexer.yylineno;
                yyloc = lexer.yylloc;
                symbol = lex();
            }

            // try to recover from error
            if (error_rule_depth === false) {
                throw new Error(errStr || 'Parsing halted. No suitable error recovery rule available.');
            }
            popStack(error_rule_depth);

            preErrorSymbol = (symbol == TERROR ? null : symbol); // save the lookahead token
            symbol = TERROR;         // insert generic error symbol as new lookahead
            state = stack[stack.length-1];
            action = table[state] && table[state][TERROR];
            recovering = 3; // allow 3 real symbols to be shifted before reporting a new error
        }

        // this shouldn't happen, unless resolve defaults are off
        if (action[0] instanceof Array && action.length > 1) {
            throw new Error('Parse Error: multiple actions possible at state: '+state+', token: '+symbol);
        }

        switch (action[0]) {
            case 1: // shift
                //this.shiftCount++;

                stack.push(symbol);
                vstack.push(lexer.yytext);
                lstack.push(lexer.yylloc);
                stack.push(action[1]); // push state
                symbol = null;
                if (!preErrorSymbol) { // normal execution/no error
                    yyleng = lexer.yyleng;
                    yytext = lexer.yytext;
                    yylineno = lexer.yylineno;
                    yyloc = lexer.yylloc;
                    if (recovering > 0) {
                        recovering--;
                    }
                } else {
                    // error just occurred, resume old lookahead f/ before error
                    symbol = preErrorSymbol;
                    preErrorSymbol = null;
                }
                break;

            case 2:
                // reduce
                //this.reductionCount++;

                len = this.productions_[action[1]][1];

                // perform semantic action
                yyval.$ = vstack[vstack.length-len]; // default to $$ = $1
                // default location, uses first token for firsts, last for lasts
                yyval._$ = {
                    first_line: lstack[lstack.length-(len||1)].first_line,
                    last_line: lstack[lstack.length-1].last_line,
                    first_column: lstack[lstack.length-(len||1)].first_column,
                    last_column: lstack[lstack.length-1].last_column
                };
                if (ranges) {
                  yyval._$.range = [lstack[lstack.length-(len||1)].range[0], lstack[lstack.length-1].range[1]];
                }
                r = this.performAction.apply(yyval, [yytext, yyleng, yylineno, sharedState.yy, action[1], vstack, lstack].concat(args));

                if (typeof r !== 'undefined') {
                    return r;
                }

                // pop off stack
                if (len) {
                    stack = stack.slice(0,-1*len*2);
                    vstack = vstack.slice(0, -1*len);
                    lstack = lstack.slice(0, -1*len);
                }

                stack.push(this.productions_[action[1]][0]);    // push nonterminal (reduce)
                vstack.push(yyval.$);
                lstack.push(yyval._$);
                // goto new state = table[STATE][NONTERMINAL]
                newState = table[stack[stack.length-2]][stack[stack.length-1]];
                stack.push(newState);
                break;

            case 3:
                // accept
                return true;
        }

    }

    return true;
}};

    let idNodos = 0;
    function getId(){        
        return idNodos++;
    }
/* generated by jison-lex 0.3.4 */
var lexer = (function(){
var lexer = ({

EOF:1,

parseError:function parseError(str, hash) {
        if (this.yy.parser) {
            this.yy.parser.parseError(str, hash);
        } else {
            throw new Error(str);
        }
    },

// resets the lexer, sets new input
setInput:function (input, yy) {
        this.yy = yy || this.yy || {};
        this._input = input;
        this._more = this._backtrack = this.done = false;
        this.yylineno = this.yyleng = 0;
        this.yytext = this.matched = this.match = '';
        this.conditionStack = ['INITIAL'];
        this.yylloc = {
            first_line: 1,
            first_column: 0,
            last_line: 1,
            last_column: 0
        };
        if (this.options.ranges) {
            this.yylloc.range = [0,0];
        }
        this.offset = 0;
        return this;
    },

// consumes and returns one char from the input
input:function () {
        var ch = this._input[0];
        this.yytext += ch;
        this.yyleng++;
        this.offset++;
        this.match += ch;
        this.matched += ch;
        var lines = ch.match(/(?:\r\n?|\n).*/g);
        if (lines) {
            this.yylineno++;
            this.yylloc.last_line++;
        } else {
            this.yylloc.last_column++;
        }
        if (this.options.ranges) {
            this.yylloc.range[1]++;
        }

        this._input = this._input.slice(1);
        return ch;
    },

// unshifts one char (or a string) into the input
unput:function (ch) {
        var len = ch.length;
        var lines = ch.split(/(?:\r\n?|\n)/g);

        this._input = ch + this._input;
        this.yytext = this.yytext.substr(0, this.yytext.length - len);
        //this.yyleng -= len;
        this.offset -= len;
        var oldLines = this.match.split(/(?:\r\n?|\n)/g);
        this.match = this.match.substr(0, this.match.length - 1);
        this.matched = this.matched.substr(0, this.matched.length - 1);

        if (lines.length - 1) {
            this.yylineno -= lines.length - 1;
        }
        var r = this.yylloc.range;

        this.yylloc = {
            first_line: this.yylloc.first_line,
            last_line: this.yylineno + 1,
            first_column: this.yylloc.first_column,
            last_column: lines ?
                (lines.length === oldLines.length ? this.yylloc.first_column : 0)
                 + oldLines[oldLines.length - lines.length].length - lines[0].length :
              this.yylloc.first_column - len
        };

        if (this.options.ranges) {
            this.yylloc.range = [r[0], r[0] + this.yyleng - len];
        }
        this.yyleng = this.yytext.length;
        return this;
    },

// When called from action, caches matched text and appends it on next action
more:function () {
        this._more = true;
        return this;
    },

// When called from action, signals the lexer that this rule fails to match the input, so the next matching rule (regex) should be tested instead.
reject:function () {
        if (this.options.backtrack_lexer) {
            this._backtrack = true;
        } else {
            return this.parseError('Lexical error on line ' + (this.yylineno + 1) + '. You can only invoke reject() in the lexer when the lexer is of the backtracking persuasion (options.backtrack_lexer = true).\n' + this.showPosition(), {
                text: "",
                token: null,
                line: this.yylineno
            });

        }
        return this;
    },

// retain first n characters of the match
less:function (n) {
        this.unput(this.match.slice(n));
    },

// displays already matched input, i.e. for error messages
pastInput:function () {
        var past = this.matched.substr(0, this.matched.length - this.match.length);
        return (past.length > 20 ? '...':'') + past.substr(-20).replace(/\n/g, "");
    },

// displays upcoming input, i.e. for error messages
upcomingInput:function () {
        var next = this.match;
        if (next.length < 20) {
            next += this._input.substr(0, 20-next.length);
        }
        return (next.substr(0,20) + (next.length > 20 ? '...' : '')).replace(/\n/g, "");
    },

// displays the character position where the lexing error occurred, i.e. for error messages
showPosition:function () {
        var pre = this.pastInput();
        var c = new Array(pre.length + 1).join("-");
        return pre + this.upcomingInput() + "\n" + c + "^";
    },

// test the lexed token: return FALSE when not a match, otherwise return token
test_match:function(match, indexed_rule) {
        var token,
            lines,
            backup;

        if (this.options.backtrack_lexer) {
            // save context
            backup = {
                yylineno: this.yylineno,
                yylloc: {
                    first_line: this.yylloc.first_line,
                    last_line: this.last_line,
                    first_column: this.yylloc.first_column,
                    last_column: this.yylloc.last_column
                },
                yytext: this.yytext,
                match: this.match,
                matches: this.matches,
                matched: this.matched,
                yyleng: this.yyleng,
                offset: this.offset,
                _more: this._more,
                _input: this._input,
                yy: this.yy,
                conditionStack: this.conditionStack.slice(0),
                done: this.done
            };
            if (this.options.ranges) {
                backup.yylloc.range = this.yylloc.range.slice(0);
            }
        }

        lines = match[0].match(/(?:\r\n?|\n).*/g);
        if (lines) {
            this.yylineno += lines.length;
        }
        this.yylloc = {
            first_line: this.yylloc.last_line,
            last_line: this.yylineno + 1,
            first_column: this.yylloc.last_column,
            last_column: lines ?
                         lines[lines.length - 1].length - lines[lines.length - 1].match(/\r?\n?/)[0].length :
                         this.yylloc.last_column + match[0].length
        };
        this.yytext += match[0];
        this.match += match[0];
        this.matches = match;
        this.yyleng = this.yytext.length;
        if (this.options.ranges) {
            this.yylloc.range = [this.offset, this.offset += this.yyleng];
        }
        this._more = false;
        this._backtrack = false;
        this._input = this._input.slice(match[0].length);
        this.matched += match[0];
        token = this.performAction.call(this, this.yy, this, indexed_rule, this.conditionStack[this.conditionStack.length - 1]);
        if (this.done && this._input) {
            this.done = false;
        }
        if (token) {
            return token;
        } else if (this._backtrack) {
            // recover context
            for (var k in backup) {
                this[k] = backup[k];
            }
            return false; // rule action called reject() implying the next rule should be tested instead.
        }
        return false;
    },

// return next match in input
next:function () {
        if (this.done) {
            return this.EOF;
        }
        if (!this._input) {
            this.done = true;
        }

        var token,
            match,
            tempMatch,
            index;
        if (!this._more) {
            this.yytext = '';
            this.match = '';
        }
        var rules = this._currentRules();
        for (var i = 0; i < rules.length; i++) {
            tempMatch = this._input.match(this.rules[rules[i]]);
            if (tempMatch && (!match || tempMatch[0].length > match[0].length)) {
                match = tempMatch;
                index = i;
                if (this.options.backtrack_lexer) {
                    token = this.test_match(tempMatch, rules[i]);
                    if (token !== false) {
                        return token;
                    } else if (this._backtrack) {
                        match = false;
                        continue; // rule action called reject() implying a rule MISmatch.
                    } else {
                        // else: this is a lexer rule which consumes input without producing a token (e.g. whitespace)
                        return false;
                    }
                } else if (!this.options.flex) {
                    break;
                }
            }
        }
        if (match) {
            token = this.test_match(match, rules[index]);
            if (token !== false) {
                return token;
            }
            // else: this is a lexer rule which consumes input without producing a token (e.g. whitespace)
            return false;
        }
        if (this._input === "") {
            return this.EOF;
        } else {
            return this.parseError('Lexical error on line ' + (this.yylineno + 1) + '. Unrecognized text.\n' + this.showPosition(), {
                text: "",
                token: null,
                line: this.yylineno
            });
        }
    },

// return next match that has a token
lex:function lex () {
        var r = this.next();
        if (r) {
            return r;
        } else {
            return this.lex();
        }
    },

// activates a new lexer condition state (pushes the new lexer condition state onto the condition stack)
begin:function begin (condition) {
        this.conditionStack.push(condition);
    },

// pop the previously active lexer condition state off the condition stack
popState:function popState () {
        var n = this.conditionStack.length - 1;
        if (n > 0) {
            return this.conditionStack.pop();
        } else {
            return this.conditionStack[0];
        }
    },

// produce the lexer rule set which is active for the currently active lexer condition state
_currentRules:function _currentRules () {
        if (this.conditionStack.length && this.conditionStack[this.conditionStack.length - 1]) {
            return this.conditions[this.conditionStack[this.conditionStack.length - 1]].rules;
        } else {
            return this.conditions["INITIAL"].rules;
        }
    },

// return the currently active lexer condition state; when an index argument is provided it produces the N-th previous condition state, if available
topState:function topState (n) {
        n = this.conditionStack.length - 1 - Math.abs(n || 0);
        if (n >= 0) {
            return this.conditionStack[n];
        } else {
            return "INITIAL";
        }
    },

// alias for begin(condition)
pushState:function pushState (condition) {
        this.begin(condition);
    },

// return the number of states currently on the stack
stateStackSize:function stateStackSize() {
        return this.conditionStack.length;
    },
options: {},
performAction: function anonymous(yy,yy_,$avoiding_name_collisions,YY_START) {
var YYSTATE=YY_START;
switch($avoiding_name_collisions) {
case 0://Ignorar espacios
break;
case 1:this.begin('textTag'); return 9;
break;
case 2:this.begin('INITIAL'); return 11;
break;
case 3://ignorar
break;
case 4:return "lt";
break;
case 5:return "gt";
break;
case 6:return "amp";
break;
case 7:return "apos";
break;
case 8:return "quot";
break;
case 9:return 34;
break;
case 10:return 5;
break;
case 11:this.begin('comment'); return 36;
break;
case 12:this.begin('INITIAL'); return 9;
break;
case 13:/*Ignorar*/
break;
case 14:return 37;
break;
case 15:return 38;
break;
case 16:return 11;
break;
case 17:return 13;
break;
case 18:return 14;
break;
case 19:return 17;
break;
case 20:return 39;
break;
case 21:return 41;
break;
case 22:return 40
break;
case 23:return 11;
break;
case 24:return 12;
break;
case 25:return 15;
break;
case 26:return 25;
break;
case 27:return 16;
break;
case 28:return 35;
break;
case 29: return 5; 
break;
case 30:
                                agregarErrorLexico("Lexico",yy_.yytext,yy_.yylloc.first_line,yy_.yylloc.first_column+1);
                                //console.log('     error lexico '+yy_.yytext);
                                
break;
}
},
rules: [/^(?:\s+)/,/^(?:>)/,/^(?:<)/,/^(?:\s+)/,/^(?:&lt;)/,/^(?:&gt;)/,/^(?:&amp;)/,/^(?:&apos;)/,/^(?:&quot;)/,/^(?:[^<&]+)/,/^(?:$)/,/^(?:!)/,/^(?:>)/,/^(?:\s+)/,/^(?:--)/,/^(?:[^-]+)/,/^(?:<)/,/^(?:xml\b)/,/^(?:version\b)/,/^(?:encoding\b)/,/^(?:"UTF-8")/,/^(?:"ASCII")/,/^(?:"ISO-8859-1")/,/^(?:<)/,/^(?:\?)/,/^(?:=)/,/^(?:\/)/,/^(?:(["][^"\""]+["])|(['][^']+[']))/,/^(?:\w+)/,/^(?:$)/,/^(?:.)/],
conditions: {"comment":{"rules":[12,13,14,15],"inclusive":false},"textTag":{"rules":[2,3,4,5,6,7,8,9,10],"inclusive":false},"INITIAL":{"rules":[0,1,11,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30],"inclusive":true}}
});
return lexer;
})();
parser.lexer = lexer;
function Parser () {
  this.yy = {};
}
Parser.prototype = parser;parser.Parser = Parser;
return new Parser;
})();


if (typeof require !== 'undefined' && typeof exports !== 'undefined') {
exports.parser = AnalyzerXML;
exports.Parser = AnalyzerXML.Parser;
exports.parse = function () { return AnalyzerXML.parse.apply(AnalyzerXML, arguments); };
exports.main = function commonjsMain (args) {
    if (!args[1]) {
        console.log('Usage: '+args[0]+' FILE');
        process.exit(1);
    }
    var source = require('fs').readFileSync(require('path').normalize(args[1]), "utf8");
    return exports.parser.parse(source);
};
if (typeof module !== 'undefined' && require.main === module) {
  exports.main(process.argv.slice(1));
}
}